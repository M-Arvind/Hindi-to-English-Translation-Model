{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hindi-English Machine translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1GmlJ2Me9MhlVyb_5IyP44aRWlQhtI0pN",
      "authorship_tag": "ABX9TyM3T77+DdS9IgtOk0YB3qmt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-Arvind/Hindi-to-English-translation-model/blob/main/Hindi_English_Machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfuxsy96XZdH",
        "outputId": "815bf1c4-90bb-48c6-93fb-1667cb3fbee1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulfcaMUTXo0D"
      },
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Bidirectional, Concatenate, Dropout\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.train import latest_checkpoint\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpgb4BsVXrKq"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Hindi_English_Truncated_Corpus.csv', encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cAvCKWgVmTV"
      },
      "source": [
        "data = data[data['source'] == 'ted']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozOXqGbTVqvh"
      },
      "source": [
        "data = data.sample(n = 10000, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "Svp-DKBPLeHY",
        "outputId": "818d2387-7b27-4186-8652-61b00d5360b7"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>117380</th>\n",
              "      <td>ted</td>\n",
              "      <td>So another thing the robot can do</td>\n",
              "      <td>एक और बात जो रोबोट कर सकते हैं</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26491</th>\n",
              "      <td>ted</td>\n",
              "      <td>that makes it really easy for publishers right...</td>\n",
              "      <td>जो प्रकाशकों के लिए इस सामाग्री को बनाना आसान ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112352</th>\n",
              "      <td>ted</td>\n",
              "      <td>from that teacher, Mrs. Posten</td>\n",
              "      <td>उसी शिक्षिका का, श्रीमती पोस्टन(Mrs. Posten)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97358</th>\n",
              "      <td>ted</td>\n",
              "      <td>which no child would play inside the classroom...</td>\n",
              "      <td>जिसे कोई बच्चा कक्षा में या घर पर नहीं खेलेगा.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71183</th>\n",
              "      <td>ted</td>\n",
              "      <td>Do you have any recommendations?”</td>\n",
              "      <td>क्या आपकी नज़र में कोई है?”</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65655</th>\n",
              "      <td>ted</td>\n",
              "      <td>A friend of mine did that - Richard Bollingbroke.</td>\n",
              "      <td>जिसे मेरे एक मित्र रिचर्ड बोलिंगब्रोक(Richard ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72438</th>\n",
              "      <td>ted</td>\n",
              "      <td>or this year's floods.</td>\n",
              "      <td>और इस साल आये बाढ़ के बाद प्रकट किया |</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11430</th>\n",
              "      <td>ted</td>\n",
              "      <td>struggle to get by.</td>\n",
              "      <td>मामूली चीजो केलिए संघर्ष कर रहे है.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16594</th>\n",
              "      <td>ted</td>\n",
              "      <td>are giving some people a sense of, “Gosh, well...</td>\n",
              "      <td>कुछ लोगों को यह महसूस करवा रहे हैं ,“ हे भगवान...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98007</th>\n",
              "      <td>ted</td>\n",
              "      <td>while holding a pencil in their mouth</td>\n",
              "      <td>जब उन्होंने अपने मुहं में एक पेंसिल पकड़ी हो</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       source  ...                                     hindi_sentence\n",
              "117380    ted  ...                     एक और बात जो रोबोट कर सकते हैं\n",
              "26491     ted  ...  जो प्रकाशकों के लिए इस सामाग्री को बनाना आसान ...\n",
              "112352    ted  ...       उसी शिक्षिका का, श्रीमती पोस्टन(Mrs. Posten)\n",
              "97358     ted  ...     जिसे कोई बच्चा कक्षा में या घर पर नहीं खेलेगा.\n",
              "71183     ted  ...                        क्या आपकी नज़र में कोई है?”\n",
              "...       ...  ...                                                ...\n",
              "65655     ted  ...  जिसे मेरे एक मित्र रिचर्ड बोलिंगब्रोक(Richard ...\n",
              "72438     ted  ...             और इस साल आये बाढ़ के बाद प्रकट किया |\n",
              "11430     ted  ...                मामूली चीजो केलिए संघर्ष कर रहे है.\n",
              "16594     ted  ...  कुछ लोगों को यह महसूस करवा रहे हैं ,“ हे भगवान...\n",
              "98007     ted  ...       जब उन्होंने अपने मुहं में एक पेंसिल पकड़ी हो\n",
              "\n",
              "[10000 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az3Ncwy6XuXp"
      },
      "source": [
        "def clean_text(text):\n",
        "    text = str(text)\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"what is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"n't\", \" not\", text)\n",
        "    text = re.sub(r\"n'\", \"ng\", text)\n",
        "    text = re.sub(r\"'bout\", \"about\", text)\n",
        "    text = re.sub(r\"'til\", \"until\", text)\n",
        "    \n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEsCmQMyXwfy"
      },
      "source": [
        "data['english_sentence'] = data['english_sentence'].apply(lambda x: clean_text(x))\n",
        "data['hindi_sentence'] = data['hindi_sentence'].apply(lambda x: clean_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB0n_QrGXyci"
      },
      "source": [
        "data['english_sentence']=data['english_sentence'].apply(lambda x: x.lower())\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.lower())\n",
        "data['english_sentence']=data['english_sentence'].apply(lambda x: x.strip())\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK4tva0XXz1K"
      },
      "source": [
        "english_filters = '।!“”1234567890\"#$%&\\'()*+,-./:;=?@[\\\\]^<>`{|}~' \n",
        "hindi_filters = '।!“”२३०८१५७९४६1234567890abcdefghijklmnopqrstuvwxyz\"#$%&\\'()*+,-./:;=?@[\\\\]^<>`{|}~' \n",
        "data['english_sentence'] = data['english_sentence'].apply(lambda x : ''.join(y for y in x if y not in english_filters))\n",
        "data['hindi_sentence'] = data['hindi_sentence'].apply(lambda x : ''.join(y for y in x if y not in hindi_filters))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LUhMRMDX5dr"
      },
      "source": [
        "data['hindi_sentence'] = data['hindi_sentence'].apply(lambda x: 'START_ '+ x + ' _END')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwlJkX2HX7Fr"
      },
      "source": [
        "all_eng_words=set()\n",
        "for eng in data['english_sentence']:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "\n",
        "all_hindi_words=set()\n",
        "for hin in data['hindi_sentence']:\n",
        "    for word in hin.split():\n",
        "        if word not in all_hindi_words:\n",
        "            all_hindi_words.add(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCqwTqb7X9oR"
      },
      "source": [
        "data['length_eng_sentence']=data['english_sentence'].apply(lambda x:len(x.split()))\n",
        "data['length_hin_sentence']=data['hindi_sentence'].apply(lambda x:len(x.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6Sduh4pK1cX"
      },
      "source": [
        "for x in data['length_eng_sentence']:\n",
        "  if x>50:\n",
        "    print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xesfSSwCI9W2",
        "outputId": "b508594b-70e2-44c5-e806-bcbf7b9c54f8"
      },
      "source": [
        "len(all_eng_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8238"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVebMipJX_26"
      },
      "source": [
        "max_length_src=max(data['length_eng_sentence'])\n",
        "max_length_tar=max(data['length_hin_sentence'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPrF926dJBmQ",
        "outputId": "ba37549c-d410-434c-cda6-3d147f6b0b2d"
      },
      "source": [
        "max_length_tar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNmpbGgkYCdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca56d43-7406-47cb-ca74-0f5bd67a64d5"
      },
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_hindi_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_hindi_words)\n",
        "num_encoder_tokens, num_decoder_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8238, 9788)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMHop9THYELK"
      },
      "source": [
        "num_encoder_tokens += 1\n",
        "num_decoder_tokens += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ78fm-dYGG6"
      },
      "source": [
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQc5TOOcYJUo"
      },
      "source": [
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7w7WuXNYLFy"
      },
      "source": [
        "data = shuffle(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BnIk2WzYMzS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6025464b-9049-4935-8920-3e9cbd52b2f3"
      },
      "source": [
        "X, y = data['english_sentence'], data['hindi_sentence']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5,random_state=42)\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5000,), (5000,))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw7xgUp-YPPX"
      },
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 32):\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word]\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] \n",
        "                    if t>0:\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8Ao_NXSYRDf"
      },
      "source": [
        "Dim = 130\n",
        "latent_dim = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5tTorgiYSbY"
      },
      "source": [
        "train_samples = len(X_train)\n",
        "test_samples = len(X_test)\n",
        "batch_size = 32\n",
        "epochs = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMoimD8EYT-_"
      },
      "source": [
        "encoder_inputs = Input(shape=(None,))\n",
        "encoder_emd = Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(Dim,return_sequences=True, return_state=True)(encoder_emd)\n",
        "encoder_lstm2 = LSTM(Dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm2(encoder_lstm)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "decoder_emd = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)(decoder_inputs)\n",
        "decoder_lstm = LSTM(Dim, return_sequences=True, return_state=True)\n",
        "decoder_output, _, _ = decoder_lstm(decoder_emd, initial_state = encoder_states)\n",
        "\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_output)\n",
        "\n",
        "Model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJfjSpMGYVuX"
      },
      "source": [
        "callback = EarlyStopping(monitor='accuracy', verbose=1, patience= 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WtXQpwCYXcu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e155ab33-efa7-43d9-bf82-762d9d6361a6"
      },
      "source": [
        "Model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 150)    1235850     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, None, 130),  146120      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 150)    1468350     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 130), (None, 135720      lstm[0][0]                       \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 130),  146120      embedding_2[0][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 9789)   1282359     lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 4,414,519\n",
            "Trainable params: 4,414,519\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTmJ0Aj1YZJn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e06610-50cd-4b68-d4e9-8d3dea0320f1"
      },
      "source": [
        "Model.compile(optimizer=Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.001), loss ='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk0eU5D_YajP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8de8a49-aaa2-47dc-80f0-328b88a7ab40"
      },
      "source": [
        "history = Model.fit_generator(generator = generate_batch(X_train, y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=train_samples//batch_size,\n",
        "                    epochs = epochs,\n",
        "                    validation_data = generate_batch(X_test, y_test, batch_size=batch_size),\n",
        "                    validation_steps = test_samples//batch_size,\n",
        "                    callbacks=callback)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "156/156 [==============================] - 39s 142ms/step - loss: 1.8354 - accuracy: 0.1396 - val_loss: 1.6871 - val_accuracy: 0.1726\n",
            "Epoch 2/30\n",
            "156/156 [==============================] - 17s 109ms/step - loss: 1.5511 - accuracy: 0.1896 - val_loss: 1.6765 - val_accuracy: 0.1911\n",
            "Epoch 3/30\n",
            "156/156 [==============================] - 17s 110ms/step - loss: 1.4459 - accuracy: 0.2180 - val_loss: 1.6873 - val_accuracy: 0.1958\n",
            "Epoch 4/30\n",
            "156/156 [==============================] - 17s 110ms/step - loss: 1.3427 - accuracy: 0.2445 - val_loss: 1.7103 - val_accuracy: 0.1982\n",
            "Epoch 5/30\n",
            "156/156 [==============================] - 17s 112ms/step - loss: 1.2426 - accuracy: 0.2652 - val_loss: 1.7398 - val_accuracy: 0.2005\n",
            "Epoch 6/30\n",
            "156/156 [==============================] - 17s 109ms/step - loss: 1.1416 - accuracy: 0.2934 - val_loss: 1.7800 - val_accuracy: 0.2021\n",
            "Epoch 7/30\n",
            "156/156 [==============================] - 17s 111ms/step - loss: 1.0508 - accuracy: 0.3281 - val_loss: 1.8137 - val_accuracy: 0.2003\n",
            "Epoch 8/30\n",
            "156/156 [==============================] - 17s 110ms/step - loss: 0.9735 - accuracy: 0.3630 - val_loss: 1.8482 - val_accuracy: 0.1960\n",
            "Epoch 9/30\n",
            "156/156 [==============================] - 17s 109ms/step - loss: 0.9012 - accuracy: 0.4017 - val_loss: 1.8823 - val_accuracy: 0.1967\n",
            "Epoch 10/30\n",
            "156/156 [==============================] - 17s 108ms/step - loss: 0.8387 - accuracy: 0.4323 - val_loss: 1.9098 - val_accuracy: 0.1971\n",
            "Epoch 11/30\n",
            "156/156 [==============================] - 17s 106ms/step - loss: 0.7858 - accuracy: 0.4648 - val_loss: 1.9461 - val_accuracy: 0.1956\n",
            "Epoch 12/30\n",
            "156/156 [==============================] - 17s 106ms/step - loss: 0.7393 - accuracy: 0.4947 - val_loss: 1.9695 - val_accuracy: 0.1912\n",
            "Epoch 13/30\n",
            "156/156 [==============================] - 17s 107ms/step - loss: 0.6965 - accuracy: 0.5211 - val_loss: 1.9858 - val_accuracy: 0.1905\n",
            "Epoch 14/30\n",
            "156/156 [==============================] - 17s 107ms/step - loss: 0.6561 - accuracy: 0.5461 - val_loss: 2.0145 - val_accuracy: 0.1900\n",
            "Epoch 15/30\n",
            "156/156 [==============================] - 17s 106ms/step - loss: 0.6207 - accuracy: 0.5711 - val_loss: 2.0401 - val_accuracy: 0.1928\n",
            "Epoch 16/30\n",
            "156/156 [==============================] - 17s 107ms/step - loss: 0.5899 - accuracy: 0.5913 - val_loss: 2.0630 - val_accuracy: 0.1885\n",
            "Epoch 17/30\n",
            "156/156 [==============================] - 17s 107ms/step - loss: 0.5645 - accuracy: 0.6083 - val_loss: 2.0826 - val_accuracy: 0.1868\n",
            "Epoch 18/30\n",
            "156/156 [==============================] - 17s 107ms/step - loss: 0.5379 - accuracy: 0.6268 - val_loss: 2.1034 - val_accuracy: 0.1870\n",
            "Epoch 19/30\n",
            "156/156 [==============================] - 17s 107ms/step - loss: 0.5147 - accuracy: 0.6440 - val_loss: 2.1245 - val_accuracy: 0.1860\n",
            "Epoch 20/30\n",
            "156/156 [==============================] - 17s 107ms/step - loss: 0.4977 - accuracy: 0.6543 - val_loss: 2.1484 - val_accuracy: 0.1870\n",
            "Epoch 21/30\n",
            "156/156 [==============================] - 17s 109ms/step - loss: 0.4817 - accuracy: 0.6653 - val_loss: 2.1695 - val_accuracy: 0.1870\n",
            "Epoch 22/30\n",
            "156/156 [==============================] - 17s 109ms/step - loss: 0.4615 - accuracy: 0.6806 - val_loss: 2.1911 - val_accuracy: 0.1861\n",
            "Epoch 23/30\n",
            "156/156 [==============================] - 17s 108ms/step - loss: 0.4416 - accuracy: 0.6935 - val_loss: 2.2148 - val_accuracy: 0.1868\n",
            "Epoch 24/30\n",
            "156/156 [==============================] - 17s 107ms/step - loss: 0.4257 - accuracy: 0.7072 - val_loss: 2.2334 - val_accuracy: 0.1872\n",
            "Epoch 25/30\n",
            "156/156 [==============================] - 17s 111ms/step - loss: 0.4140 - accuracy: 0.7151 - val_loss: 2.2500 - val_accuracy: 0.1860\n",
            "Epoch 26/30\n",
            "156/156 [==============================] - 17s 108ms/step - loss: 0.4006 - accuracy: 0.7241 - val_loss: 2.2667 - val_accuracy: 0.1863\n",
            "Epoch 27/30\n",
            "156/156 [==============================] - 16s 105ms/step - loss: 0.3862 - accuracy: 0.7339 - val_loss: 2.2855 - val_accuracy: 0.1867\n",
            "Epoch 28/30\n",
            "156/156 [==============================] - 17s 110ms/step - loss: 0.3723 - accuracy: 0.7418 - val_loss: 2.3040 - val_accuracy: 0.1871\n",
            "Epoch 29/30\n",
            "156/156 [==============================] - 17s 110ms/step - loss: 0.3587 - accuracy: 0.7534 - val_loss: 2.3206 - val_accuracy: 0.1866\n",
            "Epoch 30/30\n",
            "156/156 [==============================] - 17s 109ms/step - loss: 0.3481 - accuracy: 0.7601 - val_loss: 2.3366 - val_accuracy: 0.1844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl8pYwApYdnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3996800-2bb7-4ada-e384-d889543359d0"
      },
      "source": [
        "Model.save('drive/MyDrive/saved_model/my_model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/saved_model/my_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/saved_model/my_model/assets\n"
          ]
        }
      ]
    }
  ]
}